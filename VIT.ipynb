{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kMVr2bkyh7wa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKe13CIrzvXt",
    "outputId": "8b951b0f-df22-4c5b-d440-1fcfdca2dabb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f45c0256af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproducability by fixing the random seed\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jM0qYufbyvAV"
   },
   "outputs": [],
   "source": [
    "# define the VIT model\n",
    "class TransformerEncoder(nn.Module):\n",
    "  def __init__(self,n_heads, embed_dim, num_patches, hidden_dim ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.n_heads = n_heads\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.embed_dim = embed_dim\n",
    "    self.num_patches = num_patches\n",
    "\n",
    "    # input size = bs, dim, patches\n",
    "    self.norm1 = nn.LayerNorm([ num_patches,embed_dim ])\n",
    "    self.norm2 = nn.LayerNorm([num_patches,embed_dim])\n",
    "\n",
    "    self.W_Q = nn.Linear(embed_dim, n_heads*hidden_dim)   # Linear function is applied on the last dimension of the features then I need permutation\n",
    "    self.W_K = nn.Linear(embed_dim, n_heads*hidden_dim)\n",
    "    self.W_V = nn.Linear(embed_dim, n_heads*hidden_dim)\n",
    "    self.fc = nn.Linear(n_heads*hidden_dim, embed_dim)\n",
    "\n",
    "    self.ML_Linear = nn.Linear(hidden_dim*n_heads, hidden_dim)\n",
    "    self.MLP = nn.Sequential(nn.Linear(embed_dim,embed_dim), nn.GELU(), nn.Linear(embed_dim,embed_dim))\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "      x = self.norm1(x)\n",
    "      x_ = x\n",
    "\n",
    "      x_q = self.W_Q(x) # bs, n_patches, hidden_dim * n_heads\n",
    "      x_q = x_q.reshape(x.size(0), x.size(1),self.n_heads,self.hidden_dim,) # bs, n_patches ,n_heads, hidden_dim\n",
    "      x_q = x_q.permute(0,2,1,3)\n",
    "\n",
    "      x_k = self.W_K(x)\n",
    "      x_k = x_k.reshape(x.size(0), x.size(1), self.n_heads,self.hidden_dim,) # bs, n_patches ,n_heads, hidden_dim\n",
    "      x_k = x_k.permute(0,2,1,3)\n",
    "\n",
    "      x_v = self.W_Q(x)\n",
    "      x_v = x_v.reshape(x.size(0), x.size(1), self.n_heads, self.hidden_dim) # bs, n_patches ,n_heads, hidden_dim\n",
    "      x_v = x_v.permute(0,2,1,3)\n",
    "\n",
    "\n",
    "      # compute the attention score\n",
    "#       x_q = x_q.reshape(x_q.size(0)*x_q.size(1),x_q.size(2),x_q.size(3))\n",
    "#       x_k = x_k.reshape(x_k.size(0)*x_k.size(1),x_k.size(2),x_k.size(3))\n",
    "#       x_v = x_v.reshape(x_v.size(0)*x_v.size(1),x_v.size(2),x_v.size(3))\n",
    "\n",
    "      x_q = torch.transpose(x_q,2,3)\n",
    "#       scores =  torch.einsum(\"bij, bkj -> bik\", x_q, x_k)\n",
    "      scores = x_q@x_k\n",
    "      scores = scores/(self.hidden_dim**(0.5))\n",
    "      scores = torch.softmax(scores, dim=-1)\n",
    "\n",
    "      \n",
    "        \n",
    "#       attention =  torch.einsum(\"bik, bkj -> bij\", scores, x_v) #bs, n_patches, n_score_weights_per_patch= n_patches of k\n",
    "      scores = torch.transpose(scores,2,3)\n",
    "      \n",
    "      \n",
    "      attention = x_v@scores\n",
    "      \n",
    "    \n",
    "    # bs,n_patches,n_heads,embed_dim\n",
    "    \n",
    "      \n",
    "\n",
    "      attention = attention.permute(0,2,1,3)\n",
    "      attention = attention.reshape(attention.size(0),attention.size(1),attention.size(2)*attention.size(3))\n",
    "      x = self.fc(attention)\n",
    "\n",
    "      x = x + x_\n",
    "\n",
    "      x_ = self.norm2(x)\n",
    "      x = self.MLP(x)\n",
    "      x = x + x_\n",
    "      return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ybb1Tevp42gh"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Vit(nn.Module):\n",
    "  def __init__(self, patch_size, embed_dim, hidden_dim, n_heads,n_classes):\n",
    "    super().__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "\n",
    "    output:\n",
    "    \"\"\"\n",
    "    self.patch_size = patch_size\n",
    "    self.linear_embedding = nn.Conv2d(in_channels=1, out_channels=embed_dim, kernel_size=patch_size, stride=patch_size, padding=0)\n",
    "    self.classifier = nn.Linear(embed_dim+3,n_classes)\n",
    "    self.n_heads = n_heads\n",
    "    self.hidden_dim = hidden_dim\n",
    "\n",
    "  def get_positional_embeddings(self, sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.to(device)\n",
    "    assert x.size(2) % self.patch_size == 0, \"height of the image is not divideable by patch size\"\n",
    "    assert x.size(3) % self.patch_size == 0, \"width of the image is not divideable by patch size\"\n",
    "    x = self.linear_embedding(x)\n",
    "    \n",
    "    r = self.get_positional_embeddings(x.size(2)*x.size(3)+1, 3) # positional feature\n",
    "    r = r.to(device)\n",
    "    \n",
    "    r = r.transpose(0,1)\n",
    "    r = r.unsqueeze(0)\n",
    "    r = r.repeat(x.size(0),1,1) # 100, 1, 65\n",
    "    \n",
    "    x = x.flatten(start_dim=2)\n",
    "    \n",
    "    # add dummy token\n",
    "    x_CLS_token = nn.Parameter(torch.ones(x.size(0),x.size(1),1)).to(device)\n",
    "#     print(x.size(), x_CLS_token.size())\n",
    "    \n",
    "    x = torch.concat((x_CLS_token,x), dim=2) # bs, embed_dim, nums_patches + 1_(CLS)\n",
    "    x = torch.concat((x,r), dim=1)  # bs, dim(position + embed_dim), num_patches + CLS\n",
    "    \n",
    "#     print(x.size())\n",
    "    \n",
    "    x = x.permute(0, 2, 1) # bs, embed_dim, n_patches ---> bs, n_patches, embed_dim \n",
    "    TE_model = TransformerEncoder(n_heads=self.n_heads, embed_dim=x.size(2), num_patches=x.size(1), hidden_dim=self.hidden_dim).to(device)\n",
    "    \n",
    "#     TE_model_2 = TransformerEncoder(n_heads=self.n_heads, embed_dim=x.size(2), num_patches=x.size(1), hidden_dim=self.hidden_dim).to(device)\n",
    "\n",
    "#     y = TE_model_2(TE_model(x))\n",
    "    y = TE_model(x)\n",
    "\n",
    "    c = self.classifier(y[:,0,:])\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HwX6kw-WMsgd"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_dataloader, val_dataloader, lr, optimizer, loss_function, epochs, device, PATH):\n",
    "  model.to(device)\n",
    "# extract validation and report the accuracy in each epoch\n",
    "  for epoch in range(epochs+1):\n",
    "    total_loss = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "      img, labels = batch\n",
    "      img = img.to(device)\n",
    "      labels = labels.to(device)\n",
    "      y = model(img)\n",
    "\n",
    "      loss = loss_function(y, labels)\n",
    "      n_samples += img.size(0)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "      img, labels = batch\n",
    "      img = img.to(device)\n",
    "      labels = labels.to(device)\n",
    "      outputs = model(img)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "      # Update the running total of correct predictions and samples\n",
    "      total_correct += (predicted == labels).sum().item()\n",
    "      total_samples += labels.size(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the accuracy for this epoch\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "      print(\"loss: \", total_loss/n_samples, \"epoch=\", epoch, \"acc on val\", accuracy )\n",
    "      PATH_ = PATH + 'checkpoint' + str(epoch) + '.pt'\n",
    "      torch.save(model.state_dict(), PATH_)\n",
    "\n",
    "\n",
    "  return model.state_dict()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O-jBdroYZHy5"
   },
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, device):\n",
    "\n",
    "  total_correct = 0\n",
    "  total_samples = 0\n",
    "\n",
    "  for batch in test_dataloader:\n",
    "    img, labels = batch\n",
    "    img = img.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(img)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Update the running total of correct predictions and samples\n",
    "    total_correct += (predicted == labels).sum().item()\n",
    "    total_samples += labels.size(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the accuracy for this epoch\n",
    "  accuracy = 100 * total_correct / total_samples\n",
    "  print(\"accuracy\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "U-2nyakhi_mT",
    "outputId": "cad5fe4c-62d2-43ee-8266-389d43750075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code is running on device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Input size b, c, h, w\n",
    "# It is a classification task\n",
    "# For me the challenge is sequencialization of the image patches and channel handeling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Download the dataset and define the dataloader\n",
    "\n",
    "trans = transform.Compose([\n",
    "         transform.ToTensor(),\n",
    "         transform.Resize((32,32)),\n",
    "         #transform.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "         ])\n",
    "\n",
    "\n",
    "VAL_SIZE = 0.1\n",
    "train_set = dataset.MNIST(root='./datasets', train=True, download=True, transform=trans)\n",
    "test_set = dataset.MNIST(root='./datasets', train=False, download=True, transform=trans)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(train_set)),\n",
    "    train_set.targets,\n",
    "    stratify=train_set.targets,\n",
    "    test_size=VAL_SIZE,\n",
    ")\n",
    "\n",
    "# generate a subset of train and validation based on indices\n",
    "train_split = data.Subset(train_set, train_indices)\n",
    "val_split = data.Subset(train_set, val_indices)\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "train_dataloader = data.DataLoader(train_split, shuffle=True, batch_size=64)\n",
    "val_dataloader = data.DataLoader(val_split, shuffle=False, batch_size=64)\n",
    "test_dataloader = data.DataLoader(test_set, shuffle=False, batch_size=64)\n",
    "\n",
    "# define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The code is running on device: \", device)\n",
    "\n",
    "\n",
    "PATH = \"./model/\"  # folder path to save the checkpoints\n",
    "\n",
    "param = {\"patch_size\":8, \"embed_dim\":30, \"hidden_dim\":50, \"n_heads\":3, \"n_classes\":10}\n",
    "# define the mode\n",
    "model = Vit(**param)\n",
    "\n",
    "# learning rate\n",
    "lr = 0.02\n",
    "\n",
    "# training iteration\n",
    "epochs = 1500\n",
    "\n",
    "# optimizer, we can also define  a scheduler for the optimizer\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# checkpoints = train(model, train_dataloader, val_dataloader,lr, optimizer, loss_function, epochs, device, PATH)\n",
    "\n",
    "# save checkpoints\n",
    "\n",
    "# torch.save(checkpoints, PATH)\n",
    "\n",
    "# load checkpoints\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# CHECK TRANSFORMER IMPLEMENTATION FOR REPEATING THE RESNET BOCK AND FOR MATMUL N_HEADS AND FEATURE MANAGEMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Eetk3iUYjasm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 25.08\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./model/checkpoint10.pt\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "test(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuJy_TdNukZs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
